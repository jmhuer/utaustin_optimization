{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework 6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmhuer/utaustin_optimization/blob/main/homework6/homework6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpTRNuz3KDWV"
      },
      "source": [
        "# Problem Set 6\n",
        "In this problem set you will implement SGD and SVRG and compare the two to each other, and also to GD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGbibBewhGy5"
      },
      "source": [
        "# !pip install gdown\n",
        "# ! git clone https://github.com/jmhuer/optimization_tools\n",
        "# from optimization_tools.utils import download_gdrive\n",
        "\n",
        "# # we pass the ID between two slashes '/{ID}/'  \n",
        "# digits = '1X4fvOpQ2LK81-D3Fw4Oxugdvgm1dDJ3d'\n",
        "# news = '1Sc6ew-Ti8uNAPScD9P1UXPXrziPqaEwd'\n",
        "# download_gdrive(digits)\n",
        "# download_gdrive(news)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qt5K_-r6-rf"
      },
      "source": [
        "# Problem 1: Stochastic Variance Reduced Gradient Descent (SVRG)\n",
        "\n",
        "As we discussed in the video lectures, decomposable functions of the form\n",
        "$$\n",
        "\\min_{\\omega} \\left [ F(\\omega) = \\frac{1}{n} \\sum_i^n f_i(\\omega) \\right ],\n",
        "$$\n",
        "are very common in statistics/ML problems. Here, each $f_i$ corresponds to a loss for a particular training example. For\n",
        "example, if $f_i(\\omega) = (\\omega^\\top x_i - y_i)^2$, then $F(\\omega)$ is a least\n",
        "squares regression problem. The standard gradient descent (GD) update \n",
        "$$\n",
        "\\omega_t = \\omega_{t-1} - \\eta_t \\nabla F(\\omega_{t-1})\n",
        "$$\n",
        "\n",
        "evaluates the full gradient $\\nabla F(\\omega) = \\frac{1}{n} \\sum_i^n \\nabla\n",
        "f_i(\\omega)$, which requires evaluating $n$ derivatives. This can be\n",
        "prohibitively expensive when the number of training examples $n$ is large. SGD evaluates\n",
        "the gradient of one (or a small subset) of the training examples--drawn\n",
        "randomly from ${1,...n}$--per iteration:\n",
        "$$\n",
        "\\omega_t = \\omega_{t-1} - \\eta_t \\nabla f_i(\\omega_{t-1}).\n",
        "$$\n",
        "\n",
        "In expectation, the updates are equivalent, but SGD has the computational\n",
        "advantage of only evaluating a single gradient $\\nabla f_i(\\omega)$. The\n",
        "disadvatage is that the randomness introduces variance, which slows\n",
        "convergence. This was our motivation in class to introduce the SVRG algorithm.\n",
        "\n",
        "Given the dataset in **digits.zip**, plot the performance of GD, SGD, and SVRG for logistic regression with $l2$ regularization in terms of negative log likelihood on the training data against the number of gradient evaluations for a single training example (GD performs $n$ such evaluations per iteration and SGD performs $1$). Choose the $l2$ parameter to optimize performance on the test set. How does the choice of $T$ (the number of inner loops) affect the performance of SVRG? There should be one plot with a title and three lines with different colors, markers, and legend labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI9ZbgO2w7AV",
        "outputId": "4bd33f86-ec88-4233-f3d6-a1e5e7446c97"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import numpy.linalg as la\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import time\r\n",
        "import pdb\r\n",
        "from tqdm import tqdm\r\n",
        "import zipfile as zipfile\r\n",
        "\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "#sample code to load digits.zip\r\n",
        "def loaddata(filename):\r\n",
        "    data={}\r\n",
        "    with zipfile.ZipFile(filename) as z:\r\n",
        "        for filename in z.namelist():\r\n",
        "          data[filename] = pd.read_csv(z.open(filename), sep=' ', header=None)\r\n",
        "    return data\r\n",
        "\r\n",
        "digits_dict = loaddata('./digits.zip')\r\n",
        "print(digits_dict.keys())\r\n",
        "X_digits_train = digits_dict['X_digits_train.csv']\r\n",
        "X_digits_test = digits_dict['X_digits_test.csv']\r\n",
        "y_digits_train = digits_dict['y_digits_train.csv'].to_numpy(dtype=int).ravel()\r\n",
        "y_digits_test = digits_dict['y_digits_test.csv'].to_numpy(dtype=int).ravel()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['X_digits_test.csv', 'X_digits_train.csv', 'y_digits_test.csv', 'y_digits_train.csv'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VioAnFlQlli_"
      },
      "source": [
        "import numpy as np\n",
        "import numpy.random as rn\n",
        "import numpy.linalg as la\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import plotly.graph_objects as graph\n",
        "import numpy.linalg as la\n",
        "from tqdm import tqdm\n",
        "\n",
        "class MSE:\n",
        "    def __init__(self, train_data, test_data):\n",
        "        A ,b = train_data['data'], train_data['labels']\n",
        "        self.loss = lambda weight : (1./b.shape[0])*(.5)*np.sum((np.dot(A,weight)-b)**2)\n",
        "        self.grad_loss = lambda weight : (1./b.shape[0])*np.dot(A.T,np.dot(A,weight)-b)\n",
        "        #test loss\n",
        "        A_test ,b_test = test_data['data'], test_data['labels']\n",
        "        self.test_loss = lambda weights : (1./b_test.shape[0])*(.5)*np.sum((np.dot(A_test,weights)-b_test)**2)\n",
        "    def eval(self, weight):\n",
        "        return self.loss(weight) \n",
        "    def gradient(self,weight):\n",
        "        return self.grad_loss(weight) \n",
        "    def test_eval(self, weights):\n",
        "        return self.test_loss(weights) \n",
        "\n",
        "\n",
        "class SVRG:\n",
        "    def __init__(self, A, b, lmda = 1e-3):\n",
        "        self.lmda = lmda\n",
        "        self.loss = lambda weight : (1./b.shape[0])*(.5)*np.sum((np.dot(A,weight)-b)**2)\n",
        "        self.reg  = lambda weight : self.lmda*la.norm(weight,1)\n",
        "        self.grad_loss = lambda weight : (1./b.shape[0])*np.dot(A.T,np.dot(A,weight)-b)\n",
        "        self.grad_reg  = lambda weight : self.lmda*la.norm(weight,1) \n",
        "    def eval(self, weight):\n",
        "        return self.loss(weight) \n",
        "    def gradient(self,weight):\n",
        "        return self.grad_loss(weight) \n",
        "\n",
        "  "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSMBVd3Mk9eX"
      },
      "source": [
        "class GD:\n",
        "    def __init__(self, function, x_init, epochs, learning_rate):\n",
        "        self.function = function\n",
        "        self.x_init = x_init\n",
        "        self.epochs = epochs\n",
        "        self.learning_rate = learning_rate\n",
        "        self.history = {\"step\": [0],\n",
        "                        \"function_vals\": [],\n",
        "                        \"grad_vals\": [], \n",
        "                        \"x_vals\": [self.x_init], \n",
        "                        \"opt_dif\": [],\n",
        "                        \"test_loss\": []}\n",
        "    def go(self, test = False):\n",
        "        for i in range(self.epochs):\n",
        "          ##RETRIVE OLD VALS\n",
        "          x_old = self.history['x_vals'][-1]\n",
        "          ##EVALUATE HERE\n",
        "          y = self.function.eval(x_old)\n",
        "          g = self.function.gradient(x_old)\n",
        "          ##UPDATE HERE \n",
        "          x = x_old - self.learning_rate(i) * g\n",
        "          ##STORE HISTORY\n",
        "          self.history['step'].append(self.history['step'][-1] + 1)\n",
        "          self.history['function_vals'].append(float(y))\n",
        "          self.history['grad_vals'].append(g)\n",
        "          self.history['x_vals'].append(x)\n",
        "          if test:  \n",
        "              self.history['test_loss'].append(float(self.function.test_eval(x)))\n",
        "          ##CLEAN UP FOR SPARSE CASE\n",
        "          del self.history['grad_vals'][0:1]\n",
        "          del self.history['x_vals'][0:1] "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28Poj_GXyhKi"
      },
      "source": [
        "class SGD:\n",
        "    def __init__(self, function, x_init, epochs, learning_rate):\n",
        "        self.function = function\n",
        "        self.x_init = x_init\n",
        "        self.epochs = epochs\n",
        "        self.learning_rate = learning_rate\n",
        "        self.history = {\"step\": [],\n",
        "                        \"function_vals\": [],\n",
        "                        \"grad_vals\": [], \n",
        "                        \"x_vals\": [self.x_init], \n",
        "                        \"opt_dif\": [],\n",
        "                        \"test_loss\": []}      \n",
        "    def go(self, test = False):\n",
        "        for i in tqdm(range(self.epochs)):\n",
        "          for j in range(self.batch_size):\n",
        "              ##RETRIVE OLD VALS\n",
        "              x_old = self.history['x_vals'][-1]\n",
        "              ##EVALUATE HERE\n",
        "              y = self.function.eval(x_old)\n",
        "              g = self.function.gradient(x_old)\n",
        "              ##UPDATE HERE \n",
        "              x = x_old - self.learning_rate(i) * g\n",
        "              ##STORE HISTORY\n",
        "              self.history['step'].append(i)\n",
        "              self.history['function_vals'].append(float(y))\n",
        "              self.history['grad_vals'].append(g)\n",
        "              self.history['x_vals'].append(x)\n",
        "              self.history['grad_vals'].append(g)\n",
        "              self.history['x_vals'].append(x)\n",
        "              if test:  \n",
        "                  self.history['test_loss'].append(float(self.function.test_eval(x)))\n",
        "              ##CLEAN UP FOR SPARSE CASE\n",
        "              del self.history['grad_vals'][0:1]\n",
        "              del self.history['x_vals'][0:1] "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "KrOVeOSumpP2",
        "outputId": "725f0b40-e3c7-461b-b3aa-2d3bcbe2bb47"
      },
      "source": [
        "def L_M(A):\n",
        "  sm , sc = (1/A.shape[0])*la.norm(A,2)**2,(1/A.shape[0])*la.norm(A,-2)**2\n",
        "  return sm , sc\n",
        "\n",
        "train_data = {\"data\"  : X_digits_train,\n",
        "              \"labels\": y_digits_train}\n",
        "\n",
        "test_data  = {\"data\"  : X_digits_test,\n",
        "              \"labels\": y_digits_test}\n",
        "\n",
        "sm , sc = L_M(X_digits_train)\n",
        "gd    = GD(MSE(train_data, test_data), x_init = np.random.rand(X_digits_train.shape[1])*0, epochs = int(5e2), learning_rate = lambda dummy : 1/sm)\n",
        "\n",
        "gd.go(test=True)\n",
        "\n",
        "# plot the train loss\n",
        "all_history = { \"GD\"  : gd.history }\n",
        "\n",
        "fig = graph.Figure(layout = graph.Layout(title=graph.layout.Title(text=\"GD\")))\n",
        "for i in all_history:\n",
        "    fig.add_trace(graph.Scatter(x    = all_history[i][\"step\"],\n",
        "                                y    = all_history[i][\"function_vals\"],\n",
        "                                name = i))\n",
        "fig.show()\n",
        "\n",
        "\n",
        "\n",
        "# # plot the test loss\n",
        "# fig = graph.Figure(layout = graph.Layout(title=graph.layout.Title(text=\"GD\")))\n",
        "# for i in all_history:\n",
        "#     fig.add_trace(graph.Scatter(x    = all_history[i][\"step\"],\n",
        "#                                 y    = all_history[i][\"test_loss\"],\n",
        "#                                 name = i))\n",
        "# fig.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"d335c75e-a48a-4540-b293-66356a2839d4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"d335c75e-a48a-4540-b293-66356a2839d4\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'd335c75e-a48a-4540-b293-66356a2839d4',\n",
              "                        [{\"name\": \"GD\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500], \"y\": [14.128130217028382, 4.084773348346907, 4.002614928495485, 3.924787548379353, 3.85098018312264, 3.780910043225146, 3.714319630617758, 3.6509741233209323, 3.5906590508128677, 3.533178226660386, 3.4783519088842136, 3.4260151619846506, 3.3760163975988937, 3.3282160734465744, 3.2824855325881646, 3.2387059671097793, 3.1967674921906455, 3.1565683181355437, 3.118014009389474, 3.081016820818434, 3.0454951026584145, 3.0113727665221206, 2.978578805724969, 2.947046863962251, 2.9167148470499393, 2.887524573043095, 2.8594214565774565, 2.8323542237497965, 2.8062746542682797, 2.781137347971664, 2.7568995131414282, 2.733520774318731, 2.7109629975928518, 2.689190131553339, 2.6681680622978363, 2.647864481064529, 2.6282487632149767, 2.6092918574320816, 2.5909661841212017, 2.573245542111747, 2.5561050228535804, 2.539520931388655, 2.523470713454759, 2.5079328881461542, 2.492886985616229, 2.478313489360949, 2.4641937826695925, 2.4505100988717214, 2.437245475047136, 2.424383708899234, 2.4119093185221967, 2.3998075048191714, 2.388064116352518, 2.3766656164284545, 2.3655990522375223, 2.3548520258892656, 2.3444126671947796, 2.334269608064381, 2.3244119583998795, 2.314829283371872, 2.305511581982301, 2.296449266821328, 2.287633144935544, 2.279054399731607, 2.270704573845885, 2.2625755529164406, 2.254659550198926, 2.2469490919726867, 2.2394370036876268, 2.232116396806296, 2.2249806562990937, 2.2180234287537437, 2.211238611063033, 2.204620339657448, 2.1981629802517633, 2.191861118076773, 2.185709548569421, 2.179703268496328, 2.17383746748747, 2.168107519958231, 2.1625089773994968, 2.1570375610167365, 2.1516891547002253, 2.146459798309637, 2.1413456812572824, 2.1363431363751797, 2.1314486340520338, 2.126658776626988, 2.1219702930277893, 2.1173800336416604, 2.1128849654078703, 2.1084821671215552, 2.10416882493893, 2.099942228074549, 2.0957997646817663, 2.091738917908004, 2.087757262116882, 2.083852459269644, 2.0800222554587195, 2.076264477586613, 2.0725770301836235, 2.0689578923582683, 2.06540511487452, 2.061916817350298, 2.0584911855719086, 2.055126468919352, 2.0518209778977012, 2.0485730817699457, 2.0453812062869186, 2.042243831510132, 2.039159489723536, 2.036126763430387, 2.033144283431607, 2.0302107269821543, 2.0273248160221033, 2.024485315479264, 2.021691031640318, 2.0189408105875946, 2.0162335366987123, 2.0135681312064526, 2.0109435508163487, 2.0083587863795715, 2.005812861618804, 2.003304831904904, 2.0008337830822422, 1.9983988303406879, 1.9959991171323261, 1.9936338141310415, 1.9913021182332074, 1.9890032515977836, 1.9867364607242026, 1.9845010155664882, 1.9822962086821259, 1.9801213544142544, 1.977975788105824, 1.975858865344407, 1.973769961236417, 1.971708469709538, 1.9696738028422125, 1.967665390219096, 1.9656826783114196, 1.9637251298812541, 1.9617922234087124, 1.9598834525411535, 1.9579983255635178, 1.9561363648889254, 1.9542971065687351, 1.9524800998212735, 1.9506849065784948, 1.9489111010498448, 1.9471582693026463, 1.9454260088583428, 1.9437139283039724, 1.9420216469182618, 1.940348794311759, 1.9386950100804485, 1.9370599434723172, 1.9354432530663517, 1.9338446064634798, 1.9322636799889865, 1.930700158405947, 1.929153734639247, 1.9276241095097717, 1.9261109914783685, 1.9246140963991942, 1.9231331472820854, 1.9216678740635977, 1.920218013386372, 1.9187833083865098, 1.9173635084886447, 1.9159583692084032, 1.9145676519619854, 1.913191123882571, 1.9118285576432998, 1.9104797312865707, 1.909144428059414, 1.9078224362547012, 1.9065135490579788, 1.905217564399696, 1.903934284812636, 1.9026635172943342, 1.9014050731743168, 1.9001587679859508, 1.8989244213427505, 1.8977018568189643, 1.8964909018342757, 1.8952913875424735, 1.8941031487239322, 1.8929260236817667, 1.8917598541415168, 1.890604485154236, 1.889459765002856, 1.8883255451116971, 1.8872016799590234, 1.8860880269925124, 1.8849844465475432, 1.8838908017681955, 1.8828069585308607, 1.88173278537036, 1.8806681534084984, 1.879612936284941, 1.8785670100903444, 1.8775302533016534, 1.8765025467194878, 1.8754837734075376, 1.8744738186339027, 1.8734725698143018, 1.8724799164570824, 1.871495750109969, 1.8705199643084913, 1.8695524545260223, 1.8685931181253828, 1.8676418543119395, 1.866698564088166, 1.865763150209591, 1.8648355171421038, 1.8639155710205597, 1.8630032196086426, 1.8620983722599436, 1.8612009398802045, 1.8603108348906983, 1.8594279711926975, 1.858552264132998, 1.8576836304704556, 1.8568219883435153, 1.85596725723868, 1.8551193579599, 1.854278212598851, 1.8534437445060623, 1.8526158782628777, 1.8517945396542104, 1.8509796556420774, 1.8501711543398733, 1.8493689649873708, 1.8485730179264175, 1.8477832445773097, 1.8469995774158172, 1.8462219499508399, 1.8454502967026751, 1.8446845531818779, 1.843924655868691, 1.8431705421930302, 1.842422150515003, 1.8416794201059474, 1.8409422911299733, 1.8402107046259883, 1.8394846024901956, 1.8387639274590455, 1.8380486230926318, 1.837338633758512, 1.836633904615947, 1.8359343816005345, 1.835240011409241, 1.8345507414858038, 1.8338665200065005, 1.8331872958662745, 1.8325130186652039, 1.8318436386952999, 1.8311791069276355, 1.83051937499978, 1.8298643952035443, 1.8292141204730166, 1.8285685043728874, 1.8279275010870513, 1.8272910654074797, 1.8266591527233524, 1.8260317190104491, 1.8254087208207816, 1.8247901152724715, 1.824175860039856, 1.823565913343825, 1.8229602339423732, 1.82235878112137, 1.8217615146855346, 1.8211683949496156, 1.8205793827297614, 1.8199944393350902, 1.819413526559437, 1.8188366066732866, 1.818263642415879, 1.8176945969874871, 1.817129434041862, 1.8165681176788373, 1.8160106124370907, 1.8154568832870612, 1.8149068956240137, 1.8143606152612497, 1.8138180084234585, 1.8132790417402065, 1.8127436822395595, 1.8122118973418377, 1.8116836548534974, 1.811158922961134, 1.8106376702256115, 1.810119865576302, 1.8096054783054472, 1.8090944780626288, 1.808586834849347, 1.808082519013707, 1.807581501245208, 1.807083752569637, 1.806589244344055, 1.8060979482518862, 1.805609836298095, 1.8051248808044618, 1.804643054404941, 1.8041643300411123, 1.8036886809577133, 1.8032160806982573, 1.8027465031007346, 1.8022799222933863, 1.8018163126905646, 1.8013556489886628, 1.8008979061621198, 1.8004430594595022, 1.7999910843996483, 1.7995419567678916, 1.799095652612341, 1.7986521482402371, 1.7982114202143655, 1.7977734453495373, 1.7973382007091308, 1.7969056636016916, 1.7964758115775945, 1.7960486224257608, 1.7956240741704337, 1.7952021450680085, 1.7947828136039161, 1.7943660584895609, 1.7939518586593102, 1.7935401932675317, 1.7931310416856867, 1.7927243834994628, 1.7923201985059654, 1.7919184667109451, 1.7915191683260774, 1.7911222837662857, 1.7907277936471075, 1.7903356787821014, 1.7899459201803014, 1.7895584990437081, 1.78917339676482, 1.7887905949242089, 1.7884100752881273, 1.78803181980616, 1.787655810608909, 1.7872820300057184, 1.7869104604824297, 1.786541084699177, 1.786173885488216, 1.7858088458517847, 1.7854459489599968, 1.7850851781487733, 1.7847265169177964, 1.7843699489285036, 1.7840154580021086, 1.7836630281176493, 1.7833126434100712, 1.7829642881683379, 1.782617946833565, 1.7822736039971903, 1.781931244399164, 1.7815908529261708, 1.7812524146098754, 1.7809159146251952, 1.7805813382885978, 1.7802486710564243, 1.7799178985232362, 1.7795890064201874, 1.7792619806134198, 1.7789368071024776, 1.7786134720187552, 1.7782919616239548, 1.7779722623085756, 1.7776543605904178, 1.777338243113116, 1.7770238966446819, 1.776711308076081, 1.7764004644198164, 1.7760913528085445, 1.7757839604936998, 1.7754782748441462, 1.7751742833448427, 1.7748719735955305, 1.7745713333094366, 1.7742723503119953, 1.7739750125395886, 1.773679308038303, 1.7733852249627018, 1.7730927515746182, 1.7728018762419608, 1.7725125874375374, 1.772224873737892, 1.771938723822165, 1.771654126470957, 1.7713710705652177, 1.771089545085147, 1.7708095391091068, 1.7705310418125528, 1.7702540424669768, 1.7699785304388653, 1.7697044951886702, 1.7694319262697926, 1.7691608133275831, 1.7688911460983512, 1.7686229144083898, 1.7683561081730124, 1.7680907173956026, 1.7678267321666743, 1.7675641426629474, 1.7673029391464323, 1.7670431119635266, 1.7667846515441261, 1.7665275484007426, 1.7662717931276373, 1.7660173763999634, 1.7657642889729166, 1.765512521680904, 1.765262065436715, 1.7650129112307074, 1.7647650501300032, 1.7645184732776933, 1.7642731718920528, 1.7640291372657664, 1.7637863607651632, 1.7635448338294597, 1.7633045479700147, 1.7630654947695914, 1.7628276658816278, 1.7625910530295201, 1.7623556480059104, 1.7621214426719845, 1.7618884289567807, 1.7616565988565012, 1.7614259444338418, 1.761196457817315, 1.7609681312005983, 1.7607409568418755, 1.7605149270631955, 1.7602900342498347, 1.7600662708496677, 1.7598436293725455, 1.7596221023896814, 1.7594016825330445, 1.7591823624947585, 1.7589641350265108, 1.7587469929389665, 1.7585309291011875, 1.7583159364400638, 1.7581020079397454, 1.7578891366410851, 1.7576773156410854, 1.757466538092354, 1.7572567972025637, 1.7570480862339193, 1.756840398502629, 1.7566337273783872, 1.756428066283856, 1.7562234086941584, 1.7560197481363733, 1.755817078189041, 1.7556153924816675, 1.7554146846942422, 1.7552149485567545, 1.755016177848721, 1.754818366398713, 1.7546215080838945, 1.7544255968295621, 1.7542306266086907, 1.7540365914414846, 1.7538434853949338, 1.753651302582375, 1.7534600371630575, 1.7532696833417138, 1.7530802353681363, 1.752891687536754, 1.7527040341862228, 1.7525172696990103, 1.7523313885009926, 1.7521463850610512, 1.7519622538906765, 1.7517789895435754, 1.7515965866152818, 1.751415039742774, 1.7512343436040918, 1.7510544929179646, 1.750875482443436, 1.750697306979498, 1.750519961364726, 1.7503434404769198, 1.7501677392327464, 1.74999285258739, 1.7498187755342014, 1.7496455031043536, 1.749473030366502, 1.7493013524264456, 1.749130464426794, 1.7489603615466378, 1.7487910390012193, 1.7486224920416138]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"GD\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d335c75e-a48a-4540-b293-66356a2839d4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFOdFTo57S98"
      },
      "source": [
        "# Problem 2: Newsgroup Dataset Optimization\n",
        "\n",
        "Using any approach, optimize performance of logistic regression on the test set in **news.zip** and compare the performance of your approach to standard SGD. This dataset is the full-dimensional newsgroup dataset (as opposed to the compressed version you worked with previously). The $X$ matrices are stored in sparse matrix format and can be read using scipy.io.mmread. As the dataset is large and high-dimensional, you will have to decide on how best to allocate your computational resources. Try to utilize the sparsity of the data (i.e., don't just convert it to a dense matrix and spend all your time multiplying zeros). You may use any of the techniques covered in class or ideas from outside class (e.g., momentum, variance reduction, minibatches, adaptive learning rates, preprocessing). Describe your methodology and comment on what you found improved performance and why. Plot the performance (negative log likelihood) of your method against standard SGD in terms of the number of gradient evaluations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF0Wc09XKhMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9810989e-b8ae-42c8-c4e2-8c284daae5db"
      },
      "source": [
        "from scipy.io import mmread\r\n",
        "import sklearn.feature_selection\r\n",
        "import zipfile as zipfile\r\n",
        "\r\n",
        "\r\n",
        "#sample code to load news.zip\r\n",
        "def loadnewsdata(filename='./news.zip'):\r\n",
        "    data={}\r\n",
        "    with zipfile.ZipFile(filename) as z:\r\n",
        "        for filename in z.namelist():\r\n",
        "          if 'csv' in filename:\r\n",
        "            data[filename] = pd.read_csv(z.open(filename), sep=' ', header=None)\r\n",
        "          elif 'mtx' in filename:\r\n",
        "            data[filename] = mmread(z.open(filename))\r\n",
        "          else:\r\n",
        "            raise Exception('unexpected filetype') \r\n",
        "    return data\r\n",
        "\r\n",
        "news_dict = loadnewsdata('./news.zip')\r\n",
        "print(news_dict.keys())\r\n",
        "X_news_train = news_dict['X_news_train.mtx']\r\n",
        "X_news_test = news_dict['X_news_test.mtx']\r\n",
        "y_news_train = news_dict['y_news_train.csv'].to_numpy(dtype=int).ravel()\r\n",
        "y_news_test = news_dict['y_news_test.csv'].to_numpy(dtype=int).ravel()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['X_news_test.mtx', 'X_news_train.mtx', 'y_news_test.csv', 'y_news_train.csv'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBStmWK0ibz_"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Qqhhds9xa3G"
      },
      "source": [
        "#this logistic regression is for sparse csr arrays\n",
        "\n",
        "##implemnted in uch as way to pass numpy array and you convert to crs \n",
        "##longer processing, but safe either way I think. Cleaner implemtnation\n",
        "class csrLogistic_loss:\n",
        "    def __init__(self, train_data, test_data, mou=0.0001):\n",
        "        #all data is csr format sparse matrix\n",
        "        self.X = train_data['data']\n",
        "        self.Y = train_data['labels']\n",
        "        self.X_test = test_data['data']\n",
        "        self.Y_test = test_data['labels']\n",
        "        self.N = np.shape(self.X.toarray())\n",
        "        self.N_test = np.shape(self.X_test.toarray())\n",
        "        self.mou = mou\n",
        "        #pre_compute some quanities\n",
        "        # Z_tr,Z_te=[],[]\n",
        "        # for j in range(len(np.unique(self.Y))):\n",
        "        #     Z_tr.append(np.sum(self.X.toarray()[np.where(self.Y==j)[0],:],axis=0))\n",
        "        #     Z_te.append(np.sum(self.X_test.toarray()[np.where(self.Y_test==j)[0],:],axis=0))\n",
        "        # self.Z = csr_matrix(np.asarray(Z_tr).T)\n",
        "        # self.Z_test = csr_matrix(np.asarray(Z_te).T)\n",
        "\n",
        "        #for testing we pre_compute Zs before initializing to avoid having to do this everytime I run\n",
        "        self.Z =  Z\n",
        "        self.Z_test = Z_test\n",
        "    def eval(self, weights):\n",
        "        weights = csr_matrix(weights)\n",
        "        loss = (1./self.N[0])*(((weights.T @ self.Z).diagonal().sum()) +np.sum(np.log(np.sum(np.exp(-(self.X @ weights).toarray()),axis=1))))\n",
        "        reg=self.mou*la.norm(weights.toarray(),'fro')**2\n",
        "        return loss + reg\n",
        "    def gradient(self,weights):\n",
        "        return self.subgradient(weights)\n",
        "    def subgradient(self,weights):\n",
        "        weights = csr_matrix(weights)\n",
        "        w=csr_matrix((np.exp(-(self.X @ weights).toarray()).T/np.sum(np.exp(-(self.X @ weights).toarray()),axis=1)).T)\n",
        "        g_loss=(1./self.N[1])*(self.Z + (-self.X.T @ w))\n",
        "        g_reg=2*self.mou*weights\n",
        "        return g_loss + g_reg\n",
        "    def test_eval(self, weights):\n",
        "        weights = csr_matrix(weights)\n",
        "        loss = (1./self.N_test[0])*(((weights.T @ self.Z_test).diagonal().sum()) +np.sum(np.log(np.sum(np.exp(-(self.X_test @ weights).toarray()),axis=1))))\n",
        "        reg=self.mou*la.norm(weights.toarray(),'fro')**2\n",
        "        return loss # no reg term for testing"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QmJAMs27Hd1"
      },
      "source": [
        "#this logsitc regression for np arrays\n",
        "class Logistic_loss:\n",
        "    def __init__(self, train_data, test_data, mou=0.0001):\n",
        "        self.X = train_data['data']\n",
        "        self.Y = train_data['labels']\n",
        "        self.X_test = test_data['data']\n",
        "        self.Y_test = test_data['labels']\n",
        "        self.N = np.shape(self.X)\n",
        "        self.mou = mou\n",
        "        #pre_compute some quanities\n",
        "        # Z_tr,Z_te=[],[]\n",
        "        # for j in range(len(np.unique(self.Y))):\n",
        "        #     Z_tr.append(np.sum(self.X.toarray()[np.where(self.Y==j)[0],:],axis=0))\n",
        "        #     Z_te.append(np.sum(self.X_test.toarray()[np.where(self.Y_test==j)[0],:],axis=0))\n",
        "        # self.Z = csr_matrix(np.asarray(Z_tr).T)\n",
        "        # self.Z_test = csr_matrix(np.asarray(Z_te).T)\n",
        "\n",
        "        #for testing we pre_compute Zs before initializing to avoid having to do this everytime I run\n",
        "        self.Z =  Z\n",
        "        self.Z_test = Z_test\n",
        "    def eval(self, weights):\n",
        "        X,Y,Z=self.X,self.Y,self.Z\n",
        "        loss=(1./Y.shape[0])*(np.trace(np.dot(weights.T,Z))+np.sum(np.log(np.sum(np.exp(-np.dot(X,weights)),axis=1))))\n",
        "        reg=self.mou*la.norm(weights,'fro')**2\n",
        "        return loss + reg\n",
        "    def gradient(self,weights):\n",
        "        return self.subgradient(weights)\n",
        "    def subgradient(self,weights):\n",
        "        n,d= self.N\n",
        "        X,Y,Z=self.X,self.Y,self.Z\n",
        "        w=(np.exp(-np.dot(X,weights)).T/np.sum(np.exp(-np.dot(X,weights)),axis=1)).T\n",
        "        g_loss=(1./Y.shape[0])*(Z+np.dot(-X.T,w))\n",
        "        g_reg=2*self.mou*weights\n",
        "        return g_loss + g_reg\n",
        "    def test_eval(self, weights):\n",
        "        X = self.X_test \n",
        "        Y = self.Y_test   \n",
        "        Z = self.Z_test\n",
        "        loss=(1./Y.shape[0])*(np.trace(np.dot(weights.T,Z))+np.sum(np.log(np.sum(np.exp(-np.dot(X,weights)),axis=1))))\n",
        "        reg=self.mou*la.norm(weights,'fro')**2\n",
        "        return loss # no reg term for testing"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHgSDTVysA02"
      },
      "source": [
        "#reduce dimension\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcztjaD44J-k"
      },
      "source": [
        "from scipy.sparse import csr_matrix\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGdiV4vrkRPo"
      },
      "source": [
        "#this is max sum columns featurizer\n",
        "\n",
        "\n",
        "# index_common_features = np.argpartition(np.array(X_news_train.sum(axis=0))[0], -500)[-500:]\n",
        "# X_news_train = csr_matrix(X_news_train.toarray()[:, index_common_features])\n",
        "# X_news_test  = csr_matrix(X_news_test.toarray()[:, index_common_features])\n",
        "\n",
        "# print(\"test reduced features size \", X_news_test.shape)\n",
        "# print(\"train reduced features size \", X_news_train.shape)\n",
        "\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# df_describe = pd.DataFrame()\n",
        "# # df_describe.describe()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NV6Bsi0KfzW"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "\n",
        "ch2 = SelectKBest(chi2, k=20)\n",
        "X_train = ch2.fit_transform(X_news_train, y_news_train)\n",
        "X_news_train = ch2.transform(X_news_train)\n",
        "X_news_test = ch2.transform(X_news_test)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh3otzTIrUHS"
      },
      "source": [
        "#for testing we pre_compute Zs before initializing to avoid having to do this everytime I run\n",
        "Z_tr,Z_te=[],[]\n",
        "for j in range(len(np.unique(y_news_train))):\n",
        "    Z_tr.append(np.sum(X_news_train.toarray()[np.where(y_news_train==j)[0],:],axis=0))\n",
        "    Z_te.append(np.sum(X_news_test.toarray()[np.where(y_news_test==j)[0],:],axis=0))\n",
        "Z = csr_matrix(np.asarray(Z_tr).T)\n",
        "Z_test = csr_matrix(np.asarray(Z_te).T)\n",
        "Z_tr,Z_te=[],[]  ##empy large list"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0350u7bInyX"
      },
      "source": [
        "#full GD approach\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VOXpfav51CmZ",
        "outputId": "06b7174e-96d8-4829-867e-cdb4f5825cb0"
      },
      "source": [
        "import scipy\n",
        "from scipy.sparse.linalg import norm\n",
        "\n",
        "\n",
        "# def L_M_sparse(A):\n",
        "#   sm , sc = (1/A.shape[0])*norm(A,'fro')**2,(1/A.shape[0])*norm(A,1)**2\n",
        "#   return sm , sc\n",
        "  \n",
        "train_data = {\"data\"  : csr_matrix(X_news_train),\n",
        "              \"labels\": csr_matrix(y_news_train)}\n",
        "\n",
        "test_data  = {\"data\"  : csr_matrix(X_news_test),\n",
        "              \"labels\": csr_matrix(y_news_test)}\n",
        "\n",
        "gd    = GD(csrLogistic_loss(train_data, test_data), x_init= csr_matrix(np.zeros((20,20))), epochs = int(1000), learning_rate = lambda s : 0.01/(s+1))\n",
        "\n",
        "gd.go(test=True)\n",
        "\n",
        "# plot the train loss\n",
        "all_history = { \"GD\"  : gd.history }\n",
        "\n",
        "fig = graph.Figure(layout = graph.Layout(title=graph.layout.Title(text=\"GD\")))\n",
        "for i in all_history:\n",
        "    fig.add_trace(graph.Scatter(x    = all_history[i][\"step\"],\n",
        "                                y    = all_history[i][\"function_vals\"],\n",
        "                                name = i))\n",
        "fig.show()\n",
        "\n",
        "\n",
        "\n",
        "# plot the test loss\n",
        "fig = graph.Figure(layout = graph.Layout(title=graph.layout.Title(text=\"GD\")))\n",
        "for i in all_history:\n",
        "    fig.add_trace(graph.Scatter(x    = all_history[i][\"step\"],\n",
        "                                y    = all_history[i][\"test_loss\"],\n",
        "                                name = i))\n",
        "fig.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"26fbe3d8-2d22-429f-b9b5-549c5d820629\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"26fbe3d8-2d22-429f-b9b5-549c5d820629\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '26fbe3d8-2d22-429f-b9b5-549c5d820629',\n",
              "                        [{\"name\": \"GD\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000], \"y\": [2.995732273553991, 2.995227847533898, 2.9949760521049638, 2.994808339302937, 2.9946826330152154, 2.994582116018705, 2.994498384341788, 2.994426637774709, 2.9943638772429404, 2.994308103961984, 2.994257919147335, 2.994212305736103, 2.9941705010893407, 2.994131918672179, 2.9940960977152757, 2.99406266966181, 2.9940313351035965, 2.9940018475031707, 2.9939740014391893, 2.993947623946292, 2.993922568020806, 2.993898707673295, 2.9938759341059438, 2.9938541527212768, 2.9938332807542802, 2.993813245378292, 2.9937939821752777, 2.9937754338895015, 2.993757549403839, 2.9937402828926563, 2.9937235931159303, 2.9937074428272687, 2.9936917982744564, 2.9936766287757104, 2.993661906358275, 2.993647605448664, 2.993633702605942, 2.993620176291068, 2.99360700666659, 2.9935941754220394, 2.9935816656211602, 2.993569461567765, 2.993557548687577, 2.9935459134238203, 2.9935345431446625, 2.9935234260609653, 2.993512551152965, 2.9935019081047622, 2.993491487245639, 2.9934812794973613, 2.993471276326759, 2.9934614697029516, 2.9934518520586937, 2.9934424162553666, 2.993433155551207, 2.9934240635724367, 2.9934151342869604, 2.9934063619803775, 2.99339774123406, 2.9933892669050923, 2.9933809341078783, 2.9933727381972606, 2.993364674753, 2.9933567395654896, 2.9933489286225816, 2.993341238097428, 2.993333664337252, 2.993326203852942, 2.993318853309422, 2.99331160951672, 2.993304469421672, 2.9932974301002044, 2.9932904887501675, 2.9932836426846436, 2.9932768893257213, 2.993270226198675, 2.9932636509265316, 2.9932571612249927, 2.993250754897675, 2.9932444298316607, 2.9932381839933204, 2.993232015424397, 2.9932259222383233, 2.99321990261677, 2.9932139548063925, 2.993208077115771, 2.9932022679125265, 2.9931965256206134, 2.993190848717746, 2.9931852357329913, 2.993179685244476, 2.993174195877238, 2.99316876630118, 2.9931633952291414, 2.993158081415068, 2.9931528236522817, 2.993147620771841, 2.9931424716409807, 2.9931373751616346, 2.9931323302690367, 2.9931273359303843, 2.993122391143572, 2.9931174949359907, 2.993112646363377, 2.9931078445087276, 2.993103088481254, 2.993098377415397, 2.993093710469884, 2.993089086826824, 2.993084505690854, 2.993079966288318, 2.993075467866483, 2.9930710096927937, 2.993066591054155, 2.993062211256251, 2.99305786962289, 2.9930535654953823, 2.993049298231936, 2.9930450672070914, 2.9930408718111634, 2.9930367114497223, 2.993032585543085, 2.9930284935258324, 2.9930244348463475, 2.993020408966366, 2.993016415360553, 2.9930124535160876, 2.9930085229322736, 2.993004623120156, 2.9930007536021592, 2.992996913911737, 2.992993103593035, 2.9929893222005637, 2.992985569298893, 2.992981844462345, 2.9929781472747075, 2.992974477328959, 2.9929708342269934, 2.9929672175793676, 2.9929636270050493, 2.992960062131176, 2.9929565225928223, 2.9929530080327815, 2.9929495181013435, 2.9929460524560882, 2.9929426107616868, 2.9929391926897053, 2.992935797918417, 2.9929324261326187, 2.992929077023462, 2.9929257502882773, 2.9929224456304113, 2.992919162759074, 2.992915901389176, 2.9929126612411903, 2.992909442040999, 2.9929062435197635, 2.992903065413783, 2.9928999074643685, 2.992896769417714, 2.992893651024779, 2.9928905520411613, 2.9928874722269927, 2.9928844113468194, 2.992881369169501, 2.9928783454681005, 2.992875340019784, 2.9928723526057244, 2.9928693830110062, 2.99286643102453, 2.992863496438925, 2.9928605790504594, 2.992857678658961, 2.9928547950677267, 2.992851928083451, 2.992849077516141, 2.9928462431790486, 2.992843424888588, 2.992840622464275, 2.9928378357286505, 2.9928350645072106, 2.9928323086283535, 2.992829567923303, 2.992826842226052, 2.9928241313733035, 2.992821435204409, 2.992818753561313, 2.9928160862885, 2.9928134332329326, 2.99281079424401, 2.9928081691735056, 2.9928055578755277, 2.9928029602064616, 2.99280037602493, 2.99279780519174, 2.9927952475698434, 2.9927927030242905, 2.9927901714221896, 2.992787652632662, 2.992785146526804, 2.992782652977648, 2.99278017186012, 2.9927777030510083, 2.9927752464289203, 2.992772801874252, 2.9927703692691483, 2.9927679484974767, 2.992765539444781, 2.9927631419982657, 2.9927607560467493, 2.9927583814806407, 2.992756018191911, 2.9927536660740586, 2.9927513250220836, 2.992748994932457, 2.9927466757031005, 2.992744367233349, 2.992742069423934, 2.9927397821769515, 2.992737505395841, 2.9927352389853583, 2.992732982851555, 2.992730736901751, 2.992728501044516, 2.9927262751896437, 2.992724059248131, 2.9927218531321587, 2.9927196567550665, 2.992717470031338, 2.9927152928765763, 2.9927131252074863, 2.9927109669418557, 2.992708817998536, 2.992706678297423, 2.9927045477594425, 2.992702426306528, 2.992700313861608, 2.992698210348586, 2.9926961156923264, 2.992694029818637, 2.9926919526542535, 2.9926898841268232, 2.9926878241648933, 2.9926857726978913, 2.992683729656115, 2.992681694970716, 2.992679668573683, 2.992677650397836, 2.992675640376806, 2.9926736384450234, 2.992671644537707, 2.992669658590851, 2.99266768054121, 2.992665710326292, 2.992663747884341, 2.992661793154328, 2.9926598460759433, 2.9926579065895766, 2.992655974636316, 2.9926540501579293, 2.9926521330968567, 2.992650223396202, 2.99264832099972, 2.9926464258518086, 2.992644537897497, 2.9926426570824356, 2.992640783352893, 2.9926389166557366, 2.9926370569384315, 2.9926352041490287, 2.992633358236158, 2.992631519149015, 2.992629686837361, 2.9926278612515067, 2.992626042342305, 2.9926242300611503, 2.9926224243599617, 2.992620625191181, 2.992618832507765, 2.9926170462631743, 2.992615266411369, 2.9926134929068016, 2.99261172570441, 2.9926099647596076, 2.9926082100282834, 2.992606461466787, 2.992604719031928, 2.992602982680968, 2.9926012523716126, 2.99259952806201, 2.9925978097107366, 2.9925960972768006, 2.992594390719631, 2.992592689999069, 2.9925909950753717, 2.9925893059091946, 2.9925876224615964, 2.992585944694027, 2.9925842725683265, 2.9925826060467164, 2.992580945091798, 2.992579289666544, 2.992577639734298, 2.9925759952587625, 2.992574356204, 2.9925727225344296, 2.992571094214817, 2.9925694712102717, 2.992567853486244, 2.9925662410085216, 2.992564633743222, 2.9925630316567884, 2.992561434715989, 2.9925598428879097, 2.992558256139952, 2.9925566744398284, 2.992555097755556, 2.992553526055456, 2.992551959308149, 2.9925503974825514, 2.992548840547869, 2.9925472884735984, 2.9925457412295176, 2.9925441987856893, 2.99254266111245, 2.9925411281804117, 2.9925395999604567, 2.9925380764237355, 2.9925365575416625, 2.992535043285911, 2.992533533628414, 2.992532028541359, 2.992530527997184, 2.992529031968577, 2.992527540428468, 2.9925260533500357, 2.9925245707066916, 2.992523092472089, 2.992521618620112, 2.992520149124879, 2.9925186839607343, 2.9925172231022494, 2.99251576652422, 2.9925143142016593, 2.992512866109801, 2.9925114222240934, 2.9925099825202, 2.99250854697399, 2.9925071155615455, 2.9925056882591536, 2.9925042650433014, 2.9925028458906806, 2.9925014307781814, 2.992500019682888, 2.992498612582082, 2.992497209453235, 2.99249581027401, 2.9924944150222563, 2.992493023676012, 2.9924916362134937, 2.9924902526131043, 2.992488872853424, 2.992487496913212, 2.9924861247714016, 2.992484756407102, 2.9924833917995914, 2.99248203092832, 2.9924806737729064, 2.9924793203131332, 2.992477970528951, 2.9924766244004686, 2.992475281907959, 2.9924739430318543, 2.9924726077527435, 2.99247127605137, 2.992469947908633, 2.9924686233055846, 2.9924673022234263, 2.992465984643511, 2.9924646705473354, 2.992463359916546, 2.9924620527329333, 2.9924607489784316, 2.9924594486351133, 2.992458151685194, 2.9924568581110274, 2.992455567895105, 2.992454281020052, 2.9924529974686305, 2.9924517172237346, 2.9924504402683887, 2.992449166585751, 2.992447896159106, 2.992446628971865, 2.992445365007568, 2.9924441042498806, 2.992442846682589, 2.992441592289605, 2.9924403410549605, 2.992439092962807, 2.992437847997416, 2.9924366061431775, 2.9924353673845956, 2.992434131706292, 2.992432899093, 2.9924316695295707, 2.9924304430009627, 2.992429219492249, 2.992427998988608, 2.9924267814753325, 2.992425566937818, 2.9924243553615697, 2.9924231467321976, 2.9924219410354165, 2.9924207382570436, 2.9924195383830003, 2.9924183413993086, 2.992417147292091, 2.992415956047571, 2.99241476765207, 2.9924135820920057, 2.9924123993538956, 2.99241121942435, 2.9924100422900777, 2.9924088679378777, 2.992407696354646, 2.9924065275273675, 2.992405361443122, 2.9924041980890768, 2.9924030374524913, 2.9924018795207115, 2.992400724281175, 2.9923995717214034, 2.9923984218290065, 2.99239727459168, 2.992396129997202, 2.9923949880334395, 2.992393848688338, 2.992392711949928, 2.992391577806322, 2.9923904462457123, 2.992389317256374, 2.9923881908266585, 2.992387066944998, 2.9923859455999047, 2.992384826779964, 2.992383710473842, 2.9923825966702786, 2.9923814853580906, 2.992380376526169, 2.9923792701634784, 2.9923781662590585, 2.9923770648020187, 2.992375965781543, 2.9923748691868877, 2.9923737750073784, 2.9923726832324107, 2.99237159385145, 2.992370506854033, 2.9923694222297614, 2.9923683399683063, 2.992367260059407, 2.9923661824928693, 2.992365107258563, 2.9923640343464255, 2.992362963746458, 2.9923618954487274, 2.992360829443363, 2.992359765720559, 2.9923587042705715, 2.992357645083717, 2.9923565881503777, 2.9923555334609953, 2.99235448100607, 2.9923534307761632, 2.992352382761898, 2.992351336953956, 2.9923502933430757, 2.9923492519200545, 2.9923482126757475, 2.9923471756010693, 2.9923461406869856, 2.992345107924525, 2.992344077304768, 2.992343048818851, 2.992342022457965, 2.992340998213357, 2.9923399760763254, 2.992338956038225, 2.992337938090461, 2.9923369222244927, 2.9923359084318326, 2.9923348967040435, 2.9923338870327383, 2.9923328794095845, 2.9923318738262963, 2.992330870274641, 2.992329868746435, 2.9923288692335417, 2.992327871727877, 2.992326876221402, 2.9923258827061283, 2.9923248911741154, 2.992323901617469, 2.992322914028341, 2.9923219283989315, 2.9923209447214876, 2.9923199629883004, 2.992318983191707, 2.9923180053240905, 2.992317029377879, 2.992316055345543, 2.9923150832195993, 2.9923141129926076, 2.992313144657172, 2.99231217820594, 2.9923112136315972, 2.992310250926878, 2.992309290084556, 2.992308331097447, 2.9923073739584076, 2.992306418660336, 2.992305465196172, 2.9923045135588935, 2.992303563741522, 2.9923026157371178, 2.992301669538778, 2.9923007251396436, 2.9922997825328914, 2.9922988417117367, 2.9922979026694376, 2.9922969653992832, 2.9922960298946064, 2.9922950961487746, 2.992294164155195, 2.9922932339073105, 2.992292305398598, 2.992291378622575, 2.992290453572793, 2.992289530242841, 2.9922886086263416, 2.9922876887169543, 2.9922867705083736, 2.9922858539943262, 2.992284939168579, 2.9922840260249277, 2.992283114557205, 2.9922822047592765, 2.9922812966250425, 2.9922803901484354, 2.99227948532342, 2.992278582143997, 2.992277680604196, 2.9922767806980834, 2.992275882419753, 2.992274985763334, 2.9922740907229857, 2.9922731972928984, 2.9922723054672966, 2.9922714152404315, 2.9922705266065885, 2.9922696395600834, 2.992268754095259, 2.9922678702064927, 2.9922669878881893, 2.992266107134783, 2.992265227940739, 2.9922643503005517, 2.9922634742087433, 2.992262599659865, 2.9922617266485, 2.9922608551692536, 2.992259985216766, 2.992259116785702, 2.9922582498707544, 2.9922573844666442, 2.9922565205681204, 2.9922556581699586, 2.992254797266962, 2.99225393785396, 2.9922530799258107, 2.992252223477396, 2.9922513685036267, 2.9922505149994367, 2.992249662959791, 2.9922488123796747, 2.992247963254102, 2.992247115578113, 2.99224626934677, 2.992245424555164, 2.9922445811984093, 2.9922437392716454, 2.992242898770034, 2.992242059688766, 2.9922412220230536, 2.9922403857681332, 2.9922395509192645, 2.9922387174717353, 2.9922378854208507, 2.9922370547619446, 2.9922362254903714, 2.992235397601509, 2.9922345710907603, 2.9922337459535497, 2.992232922185322, 2.9922320997815497, 2.992231278737723, 2.9922304590493574, 2.992229640711989, 2.992228823721176, 2.9922280080725, 2.992227193761562, 2.992226380783986, 2.992225569135418, 2.9922247588115236, 2.9922239498079914, 2.992223142120528, 2.992222335744865, 2.992221530676752, 2.99222072691196, 2.9922199244462795, 2.992219123275523, 2.9922183233955217, 2.9922175248021294, 2.992216727491215, 2.9922159314586736, 2.992215136700414, 2.9922143432123693, 2.9922135509904892, 2.9922127600307413, 2.9922119703291186, 2.9922111818816264, 2.9922103946842937, 2.9922096087331647, 2.9922088240243045, 2.992208040553797, 2.9922072583177437, 2.9922064773122643, 2.992205697533498, 2.9922049189776003, 2.992204141640746, 2.992203365519128, 2.9922025906089567, 2.992201816906459, 2.9922010444078815, 2.9922002731094866, 2.992199503007555, 2.9921987340983836, 2.9921979663782894, 2.9921971998436008, 2.99219643449067, 2.99219567031586, 2.9921949073155543, 2.992194145486153, 2.992193384824069, 2.992192625325736, 2.992191866987602, 2.9921911098061313, 2.9921903537778056, 2.9921895988991185, 2.9921888451665866, 2.9921880925767357, 2.9921873411261113, 2.992186590811272, 2.9921858416287943, 2.992185093575268, 2.9921843466473, 2.9921836008415115, 2.99218285615454, 2.992182112583036, 2.9921813701236664, 2.9921806287731143, 2.992179888528075, 2.9921791493852603, 2.9921784113413956, 2.992177674393221, 2.9921769385374923, 2.992176203770978, 2.992175470090462, 2.992174737492743, 2.9921740059746322, 2.9921732755329558, 2.9921725461645536, 2.9921718178662786, 2.9921710906350008, 2.9921703644675994, 2.99216963936097, 2.9921689153120234, 2.9921681923176786, 2.992167470374873, 2.992166749480554, 2.9921660296316857, 2.9921653108252424, 2.992164593058212, 2.9921638763275973, 2.992163160630411, 2.9921624459636806, 2.9921617323244485, 2.9921610197097643, 2.9921603081166968, 2.992159597542321, 2.9921588879837286, 2.992158179438022, 2.9921574719023187, 2.992156765373744, 2.992156059849439, 2.992155355326556, 2.992154651802258, 2.992153949273722, 2.9921532477381363, 2.992152547192701, 2.9921518476346263, 2.992151149061138, 2.992150451469471, 2.99214975485687, 2.992149059220596, 2.9921483645579188, 2.992147670866119, 2.9921469781424896, 2.9921462863843344, 2.992145595588968, 2.99214490575372, 2.992144216875924, 2.9921435289529312, 2.992142841982101, 2.9921421559608037, 2.9921414708864202, 2.9921407867563437, 2.9921401035679764, 2.9921394213187327, 2.9921387400060366, 2.992138059627323, 2.9921373801800377, 2.9921367016616367, 2.9921360240695867, 2.9921353474013626, 2.992134671654453, 2.9921339968263543, 2.992133322914575, 2.992132649916632, 2.9921319778300517, 2.9921313066523725, 2.9921306363811437, 2.992129967013921, 2.9921292985482713, 2.992128630981773, 2.9921279643120124, 2.9921272985365865, 2.9921266336531005, 2.9921259696591713, 2.9921253065524236, 2.992124644330493, 2.992123982991023, 2.9921233225316675, 2.99212266295009, 2.992122004243962, 2.992121346410966, 2.9921206894487935, 2.992120033355141, 2.9921193781277213, 2.9921187237642504, 2.992118070262456, 2.9921174176200735, 2.992116765834849, 2.992116114904535, 2.9921154648268957, 2.992114815599701, 2.9921141672207314, 2.992113519687776, 2.9921128729986317, 2.9921122271511047, 2.9921115821430093, 2.992110937972169, 2.992110294636415, 2.992109652133588, 2.9921090104615344, 2.992108369618113, 2.9921077296011873, 2.9921070904086307, 2.9921064520383243, 2.992105814488158, 2.992105177756029, 2.9921045418398426, 2.9921039067375146, 2.992103272446964, 2.9921026389661205, 2.9921020062929236, 2.9921013744253173, 2.992100743361255, 2.9921001130986995, 2.9920994836356165, 2.9920988549699836, 2.9920982270997856, 2.992097600023014, 2.9920969737376684, 2.992096348241754, 2.992095723533288, 2.9920950996102906, 2.9920944764707906, 2.9920938541128264, 2.9920932325344407, 2.9920926117336855, 2.99209199170862, 2.9920913724573097, 2.9920907539778274, 2.9920901362682546, 2.9920895193266785, 2.9920889031511924, 2.9920882877399, 2.9920876730909094, 2.992087059202335, 2.992086446072303, 2.9920858336989395, 2.9920852220803837, 2.992084611214777, 2.992084001100271, 2.9920833917350236, 2.9920827831171954, 2.992082175244961, 2.9920815681164963, 2.992080961729984, 2.992080356083617, 2.9920797511755906, 2.99207914700411, 2.9920785435673856, 2.9920779408636338, 2.992077338891077, 2.992076737647946, 2.992076137132478, 2.9920755373429144, 2.9920749382775047, 2.9920743399345047, 2.9920737423121753, 2.9920731454087837, 2.9920725492226055, 2.99207195375192, 2.992071358995014, 2.9920707649501805, 2.992070171615718, 2.9920695789899314, 2.992068987071131, 2.992068395857635, 2.992067805347765, 2.9920672155398513, 2.992066626432228, 2.9920660380232347, 2.9920654503112205, 2.992064863294536, 2.992064276971541, 2.9920636913405976, 2.9920631064000776, 2.9920625221483568, 2.9920619385838148, 2.9920613557048403, 2.992060773509826, 2.9920601919971688, 2.992059611165275, 2.992059031012553, 2.9920584515374173, 2.99205787273829, 2.9920572946135966, 2.992056717161769, 2.9920561403812447, 2.9920555642704656, 2.9920549888278805, 2.9920544140519416, 2.992053839941109, 2.992053266493847, 2.9920526937086236, 2.992052121583914, 2.9920515501182003, 2.9920509793099646, 2.9920504091576987, 2.9920498396598982, 2.9920492708150643, 2.9920487026217026, 2.992048135078324, 2.992047568183445, 2.992047001935586, 2.9920464363332746, 2.992045871375041, 2.9920453070594224, 2.9920447433849593, 2.992044180350198, 2.992043617953691, 2.9920430561939924, 2.992042495069665, 2.9920419345792735, 2.992041374721389, 2.992040815494587, 2.992040256897448, 2.9920396989285574, 2.992039141586504, 2.992038584869883, 2.9920380287772947, 2.9920374733073425, 2.9920369184586346, 2.992036364229785, 2.992035810619412, 2.992035257626137, 2.9920347052485887, 2.9920341534853976, 2.9920336023352005, 2.9920330517966387, 2.9920325018683576, 2.992031952549008, 2.9920314038372413, 2.9920308557317195, 2.992030308231104, 2.9920297613340625, 2.992029215039268, 2.9920286693453972, 2.99202812425113, 2.992027579755152, 2.9920270358561516, 2.9920264925528253, 2.992025949843867, 2.9920254077279824, 2.992024866203877, 2.992024325270261, 2.9920237849258506, 2.9920232451693645, 2.992022705999525, 2.9920221674150604, 2.992021629414703, 2.992021091997187, 2.992020555161254, 2.9920200189056474, 2.992019483229114, 2.9920189481304065, 2.992018413608282, 2.9920178796614985, 2.992017346288823, 2.9920168134890206, 2.992016281260865, 2.9920157496031314, 2.992015218514599, 2.9920146879940543, 2.992014158040283, 2.9920136286520758, 2.99201309982823, 2.9920125715675443, 2.9920120438688205, 2.9920115167308676, 2.992010990152494, 2.9920104641325156, 2.992009938669751, 2.992009413763021, 2.9920088894111525, 2.992008365612973, 2.9920078423673186, 2.9920073196730232, 2.992006797528929, 2.992006275933879, 2.9920057548867223, 2.9920052343863084, 2.9920047144314945, 2.9920041950211376, 2.9920036761541007, 2.9920031578292483, 2.9920026400454516, 2.9920021228015816, 2.9920016060965158, 2.992001089929133, 2.9920005742983173, 2.9920000592029545, 2.9919995446419367, 2.9919990306141555, 2.9919985171185104, 2.991998004153899, 2.991997491719227, 2.9919969798134023, 2.991996468435334, 2.991995957583937, 2.991995447258129, 2.9919949374568304, 2.9919944281789648, 2.9919939194234595, 2.991993411189247, 2.9919929034752593, 2.991992396280434, 2.991991889603712, 2.9919913834440366, 2.991990877800355, 2.9919903726716175, 2.991989868056777, 2.9919893639547896, 2.9919888603646156, 2.991988357285218, 2.9919878547155636, 2.991987352654619, 2.991986851101359, 2.9919863500547574, 2.9919858495137945, 2.9919853494774493, 2.9919848499447075, 2.991984350914558, 2.991983852385991, 2.9919833543579983, 2.9919828568295794]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"GD\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('26fbe3d8-2d22-429f-b9b5-549c5d820629');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"681a646e-7ab6-4a16-b1c2-39407f539db6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"681a646e-7ab6-4a16-b1c2-39407f539db6\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '681a646e-7ab6-4a16-b1c2-39407f539db6',\n",
              "                        [{\"name\": \"GD\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000], \"y\": [2.9952360927187884, 2.9949881768199735, 2.9948229604496643, 2.994699079303982, 2.9945999933144125, 2.994517434385168, 2.9944466787374497, 2.9943847744394274, 2.9943297537780906, 2.9942802395005543, 2.994235230062087, 2.994193974367001, 2.9941558946931246, 2.994120537147276, 2.9940875386380057, 2.994056604170893, 2.994027490822684, 2.993999996167729, 2.993973949750547, 2.993949206690574, 2.993925642809815, 2.993903150868019, 2.9938816376164232, 2.993861021465385, 2.993841230618563, 2.993822201565966, 2.9938038778561067, 2.9937862090874505, 2.993769150073775, 2.9937526601486617, 2.993736702582179, 2.9937212440887335, 2.99370625440948, 2.9936917059561785, 2.9936775735059116, 2.993663833938225, 2.9936504660077876, 2.9936374501469736, 2.9936247682937536, 2.9936124037411074, 2.9936003410048015, 2.993588565706911, 2.993577064472886, 2.9935658248403167, 2.9935548351778425, 2.9935440846128687, 2.993533562966978, 2.9935232606980744, 2.9935131688484238, 2.9935032789979013, 2.9934935832218112, 2.993484074052775, 2.993474744446206, 2.9934655877489886, 2.9934565976709986, 2.993447768259175, 2.9934390938738553, 2.993430569167163, 2.993422189063218, 2.993413948740004, 2.9934058436127144, 2.9933978693184464, 2.9933900217021105, 2.9933822968034387, 2.993374690844992, 2.993367200221079, 2.993359821487501, 2.9933525513520505, 2.9933453866656943, 2.993338324414395, 2.9933313617115043, 2.9933244957906813, 2.993317723999301, 2.9933110437923056, 2.993304452726466, 2.9932979484550244, 2.993291528722676, 2.9932851913608856, 2.9932789342834853, 2.993272755482561, 2.993266653024586, 2.993260625046793, 2.9932546697537563, 2.9932487854141945, 2.993242970357945, 2.9932372229731206, 2.9932315417034348, 2.9932259250456656, 2.9932203715472796, 2.9932148798041713, 2.9932094484585368, 2.9932040761968626, 2.9931987617480136, 2.9931935038814395, 2.993188301405454, 2.9931831531656243, 2.99317805804323, 2.993173014953807, 2.9931680228457624, 2.99316308069906, 2.9931581875239686, 2.9931533423598737, 2.993148544274152, 2.9931437923610824, 2.993139085740836, 2.9931344235584874, 2.9931298049830866, 2.9931252292067754, 2.9931206954439324, 2.993116202930371, 2.99311175092256, 2.9931073386968943, 2.993102965548982, 2.993098630792972, 2.99309433376091, 2.9930900738021244, 2.993085850282628, 2.9930816625845575, 2.9930775101056297, 2.9930733922586232, 2.9930693084708806, 2.993065258183827, 2.993061240852519, 2.993057255945198, 2.99305330294287, 2.9930493813389045, 2.993045490638641, 2.9930416303590133, 2.9930378000281945, 2.9930339991852493, 2.9930302273797995, 2.9930264841717054, 2.9930227691307603, 2.993019081836389, 2.9930154218773666, 2.993011788851539, 2.993008182365565, 2.993004602034653, 2.9930010474823203, 2.9929975183401534, 2.992994014247579, 2.9929905348516455, 2.9929870798068037, 2.99298364877471, 2.9929802414240205, 2.9929768574302007, 2.992973496475344, 2.992970158247987, 2.9929668424429394, 2.9929635487611175, 2.9929602769093795, 2.992957026600373, 2.99295379755238, 2.9929505894891726, 2.9929474021398694, 2.992944235238802, 2.992941088525377, 2.9929379617439515, 2.99293485464371, 2.9929317669785362, 2.9929286985069052, 2.9929256489917644, 2.9929226182004234, 2.992919605904453, 2.9929166118795756, 2.992913635905569, 2.9929106777661687, 2.992907737248972, 2.992904814145348, 2.992901908250348, 2.9928990193626235, 2.9928961472843323, 2.992893291821069, 2.99289045278178, 2.9928876299786857, 2.9928848232272105, 2.9928820323459067, 2.9928792571563863, 2.992876497483251, 2.992873753154027, 2.992871023999102, 2.992868309851655, 2.9928656105476064, 2.992862925925549, 2.992860255826695, 2.992857600094817, 2.9928549585761965, 2.9928523311195674, 2.992849717576066, 2.992847117799179, 2.992844531644695, 2.992841958970658, 2.992839399637316, 2.9928368535070815, 2.992834320444485, 2.992831800316128, 2.9928292929906446, 2.9928267983386627, 2.992824316232758, 2.99282184654742, 2.99281938915901, 2.9928169439457273, 2.9928145107875728, 2.992812089566311, 2.992809680165436, 2.992807282470141, 2.9928048963672853, 2.9928025217453555, 2.9928001584944433, 2.9927978065062084, 2.9927954656738547, 2.9927931358920943, 2.9927908170571236, 2.9927885090665955, 2.99278621181959, 2.9927839252165915, 2.992781649159458, 2.992779383551399, 2.992777128296952, 2.992774883301954, 2.992772648473522, 2.992770423720029, 2.9927682089510803, 2.9927660040774917, 2.9927638090112705, 2.9927616236655883, 2.9927594479547697, 2.992757281794262, 2.9927551251006244, 2.9927529777915027, 2.992750839785612, 2.9927487110027213, 2.9927465913636295, 2.992744480790154, 2.9927423792051098, 2.992740286532292, 2.992738202696463, 2.9927361276233304, 2.992734061239539, 2.9927320034726463, 2.992729954251116, 2.992727913504295, 2.9927258811624045, 2.9927238571565256, 2.99272184141858, 2.9927198338813223, 2.992717834478325, 2.992715843143959, 2.9927138598133936, 2.9927118844225697, 2.992709916908199, 2.992707957207744, 2.9927060052594094, 2.9927040610021303, 2.992702124375561, 2.9927001953200616, 2.9926982737766905, 2.9926963596871894, 2.992694452993978, 2.992692553640137, 2.992690661569405, 2.9926887767261614, 2.992686899055424, 2.992685028502833, 2.992683165014644, 2.9926813085377204, 2.992679459019523, 2.9926776164080993, 2.9926757806520765, 2.992673951700654, 2.9926721295035934, 2.9926703140112108, 2.992668505174365, 2.9926667029444594, 2.9926649072734217, 2.992663118113707, 2.99266133541828, 2.9926595591406193, 2.9926577892346984, 2.992656025654988, 2.992654268356444, 2.9926525172944993, 2.9926507724250624, 2.9926490337045055, 2.9926473010896646, 2.9926455745378195, 2.992643854006707, 2.9926421394544973, 2.9926404308397974, 2.992638728121643, 2.9926370312594925, 2.992635340213218, 2.9926336549431056, 2.9926319754098465, 2.992630301574531, 2.9926286333986427, 2.9926269708440567, 2.9926253138730305, 2.9926236624482, 2.9926220165325774, 2.9926203760895413, 2.992618741082834, 2.992617111476558, 2.99261548723517, 2.9926138683234766, 2.992612254706628, 2.9926106463501174, 2.9926090432197725, 2.9926074452817524, 2.992605852502547, 2.9926042648489646, 2.992602682288137, 2.9926011047875094, 2.9925995323148373, 2.992597964838185, 2.9925964023259195, 2.992594844746707, 2.9925932920695084, 2.992591744263579, 2.992590201298461, 2.992588663143981, 2.992587129770247, 2.992585601147645, 2.9925840772468355, 2.9925825580387495, 2.992581043494586, 2.9925795335858063, 2.992578028284137, 2.9925765275615586, 2.9925750313903072, 2.992573539742873, 2.992572052591991, 2.9925705699106464, 2.992569091672062, 2.992567617849706, 2.9925661484172776, 2.9925646833487147, 2.9925632226181866, 2.9925617662000885, 2.992560314069043, 2.992558866199896, 2.9925574225677134, 2.992555983147781, 2.9925545479155984, 2.9925531168468793, 2.9925516899175473, 2.992550267103736, 2.992548848381781, 2.992547433728226, 2.992546023119813, 2.992544616533483, 2.992543213946374, 2.992541815335818, 2.9925404206793407, 2.992539029954656, 2.9925376431396664, 2.9925362602124608, 2.992534881151308, 2.992533505934665, 2.9925321345411633, 2.9925307669496126, 2.992529403139001, 2.9925280430884875, 2.9925266867774027, 2.99252533418525, 2.9925239852916987, 2.9925226400765848, 2.992521298519908, 2.9925199606018333, 2.9925186263026826, 2.9925172956029393, 2.9925159684832443, 2.9925146449243942, 2.9925133249073395, 2.9925120084131827, 2.9925106954231757, 2.992509385918724, 2.9925080798813766, 2.9925067772928315, 2.992505478134928, 2.992504182389651, 2.992502890039126, 2.992501601065619, 2.9925003154515335, 2.992499033179411, 2.992497754231929, 2.9924964785919, 2.992495206242267, 2.9924939371661052, 2.9924926713466236, 2.9924914087671537, 2.9924901494111618, 2.9924888932622338, 2.992487640304085, 2.9924863905205537, 2.992485143895598, 2.9924839004133013, 2.992482660057863, 2.992481422813605, 2.9924801886649637, 2.992478957596495, 2.992477729592867, 2.9924765046388653, 2.992475282719384, 2.9924740638194334, 2.992472847924133, 2.992471635018711, 2.9924704250885066, 2.992469218118964, 2.9924680140956355, 2.992466813004179, 2.9924656148303552, 2.9924644195600303, 2.9924632271791722, 2.9924620376738496, 2.992460851030233, 2.99245966723459, 2.99245848627329, 2.992457308132798, 2.9924561327996764, 2.992454960260583, 2.9924537905022697, 2.9924526235115847, 2.992451459275466, 2.9924502977809477, 2.992449139015153, 2.9924479829652944, 2.992446829618677, 2.992445678962692, 2.9924445309848204, 2.99244338567263, 2.9924422430137745, 2.992441102995993, 2.9924399656071095, 2.9924388308350323, 2.992437698667754, 2.9924365690933477, 2.992435442099968, 2.992434317675854, 2.99243319580932, 2.9924320764887633, 2.99243095970266, 2.9924298454395615, 2.9924287336880986, 2.992427624436979, 2.992426517674987, 2.9924254133909787, 2.99242431157389, 2.9924232122127243, 2.992422115296565, 2.9924210208145645, 2.992419928755946, 2.9924188391100084, 2.9924177518661184, 2.992416667013712, 2.9924155845422966, 2.9924145044414483, 2.9924134267008102, 2.992412351310095, 2.9924112782590813, 2.992410207537614, 2.992409139135605, 2.99240807304303, 2.9924070092499315, 2.9924059477464158, 2.9924048885226506, 2.9924038315688697, 2.992402776875368, 2.9924017244325034, 2.992400674230694, 2.9923996262604207, 2.9923985805122237, 2.992397536976703, 2.9923964956445204, 2.9923954565063924, 2.992394419553098, 2.992393384775473, 2.9923923521644094, 2.992391321710859, 2.9923902934058266, 2.992389267240377, 2.992388243205627, 2.9923872212927507, 2.992386201492977, 2.9923851837975883, 2.992384168197921, 2.992383154685365, 2.9923821432513633, 2.9923811338874104, 2.9923801265850556, 2.9923791213358952, 2.9923781181315823, 2.9923771169638163, 2.992376117824348, 2.9923751207049816, 2.992374125597566, 2.992373132494003, 2.99237214138624, 2.9923711522662764, 2.9923701651261565, 2.9923691799579735, 2.992368196753869, 2.99236721550603, 2.99236623620669, 2.9923652588481295, 2.9923642834226736, 2.9923633099226943, 2.9923623383406075, 2.9923613686688744, 2.992360400900001, 2.9923594350265343, 2.9923584710410713, 2.9923575089362453, 2.9923565487047368, 2.9923555903392667, 2.992354633832602, 2.992353679177546, 2.9923527263669487, 2.992351775393699, 2.9923508262507266, 2.992349878931004, 2.992348933427541, 2.992347989733391, 2.992347047841644, 2.9923461077454325, 2.9923451694379253, 2.992344232912332, 2.992343298161901, 2.992342365179915, 2.9923414339597008, 2.9923405044946207, 2.9923395767780714, 2.9923386508034904, 2.992337726564351, 2.9923368040541622, 2.992335883266471, 2.992334964194858, 2.9923340468329425, 2.992333131174378, 2.9923322172128524, 2.9923313049420903, 2.99233039435585, 2.992329485447924, 2.99232857821214, 2.992327672642359, 2.992326768732476, 2.9923258664764196, 2.992324965868151, 2.992324066901666, 2.992323169570991, 2.9923222738701862, 2.992321379793345, 2.9923204873345886, 2.9923195964880764, 2.992318707247995, 2.9923178196085645, 2.992316933564034, 2.992316049108684, 2.9923151662368284, 2.9923142849428075, 2.992313405220996, 2.992312527065795, 2.992311650471638, 2.9923107754329874, 2.992309901944333, 2.992309030000196, 2.9923081595951286, 2.992307290723707, 2.9923064233805388, 2.9923055575602597, 2.992304693257534, 2.992303830467052, 2.992302969183534, 2.992302109401728, 2.992301251116407, 2.9923003943223745, 2.9922995390144576, 2.9922986851875124, 2.992297832836422, 2.9922969819560943, 2.992296132541465, 2.992295284587495, 2.992294438089172, 2.9922935930415067, 2.992292749439541, 2.992291907278336, 2.992291066552982, 2.9922902272585934, 2.992289389390309, 2.9922885529432914, 2.9922877179127303, 2.9922868842938395, 2.9922860520818535, 2.992285221272035, 2.992284391859668, 2.992283563840062, 2.9922827372085483, 2.9922819119604838, 2.9922810880912456, 2.9922802655962375, 2.9922794444708836, 2.9922786247106328, 2.9922778063109527, 2.9922769892673404, 2.9922761735753083, 2.9922753592303946, 2.9922745462281592, 2.992273734564184, 2.9922729242340718, 2.992272115233446, 2.992271307557956, 2.992270501203267, 2.9922696961650694, 2.992268892439073, 2.9922680900210086, 2.9922672889066275, 2.992266489091703, 2.9922656905720255, 2.9922648933434126, 2.9922640974016956, 2.9922633027427277, 2.9922625093623827, 2.9922617172565547, 2.992260926421158, 2.992260136852124, 2.9922593485454057, 2.9922585614969752, 2.9922577757028246, 2.992256991158962, 2.9922562078614163, 2.992255425806239, 2.992254644989494, 2.9922538654072683, 2.992253087055665, 2.9922523099308065, 2.992251534028835, 2.9922507593459065, 2.9922499858782015, 2.992249213621913, 2.992248442573253, 2.992247672728455, 2.992246904083764, 2.9922461366354476, 2.9922453703797878, 2.992244605313085, 2.9922438414316574, 2.9922430787318395, 2.992242317209983, 2.992241556862455, 2.992240797685642, 2.992240039675946, 2.9922392828297846, 2.992238527143593, 2.992237772613823, 2.9922370192369416, 2.992236267009432, 2.992235515927795, 2.9922347659885453, 2.9922340171882156, 2.9922332695233522, 2.992232522990519, 2.9922317775862934, 2.9922310333072697, 2.992230290150059, 2.992229548111284, 2.9922288071875864, 2.9922280673756196, 2.992227328672055, 2.9922265910735772, 2.992225854576886, 2.992225119178696, 2.9922243848757377, 2.9922236516647525, 2.9922229195425016, 2.992222188505755, 2.992221458551303, 2.9922207296759438, 2.992220001876495, 2.9922192751497874, 2.9922185494926605, 2.9922178249019753, 2.9922171013746017, 2.992216378907426, 2.9922156574973457, 2.9922149371412736, 2.992214217836135, 2.9922134995788703, 2.9922127823664306, 2.992212066195784, 2.992211351063908, 2.9922106369677937, 2.992209923904449, 2.9922092118708905, 2.9922085008641495, 2.9922077908812708, 2.9922070819193096, 2.9922063739753373, 2.9922056670464334, 2.992204961129694, 2.9922042562222257, 2.9922035523211474, 2.992202849423591, 2.992202147526701, 2.9922014466276323, 2.9922007467235545, 2.992200047811646, 2.9921993498890993, 2.9921986529531206, 2.992197957000923, 2.992197262029736, 2.9921965680367983, 2.9921958750193616, 2.992195182974687, 2.9921944919000496, 2.9921938017927348, 2.992193112650038, 2.99219242446927, 2.9921917372477496, 2.9921910509828065, 2.9921903656717825, 2.9921896813120306, 2.9921889979009157, 2.9921883154358104, 2.992187633914102, 2.9921869533331873, 2.992186273690473, 2.9921855949833756, 2.9921849172093262, 2.992184240365762, 2.9921835644501336, 2.992182889459901, 2.992182215392534, 2.992181542245515, 2.9921808700163344, 2.992180198702494, 2.992179528301505, 2.992178858810889, 2.992178190228179, 2.9921775225509153, 2.992176855776651, 2.9921761899029473, 2.992175524927377, 2.99217486084752, 2.9921741976609675, 2.992173535365321, 2.992172873958191, 2.992172213437198, 2.9921715537999716, 2.9921708950441497, 2.9921702371673833, 2.9921695801673276, 2.992168924041652, 2.9921682687880335, 2.992167614404156, 2.9921669608877157, 2.992166308236418, 2.9921656564479746, 2.9921650055201074, 2.992164355450551, 2.992163706237042, 2.9921630578773315, 2.992162410369178, 2.9921617637103477, 2.992161117898617, 2.9921604729317695, 2.992159828807599, 2.9921591855239074, 2.9921585430785047, 2.99215790146921, 2.9921572606938507, 2.992156620750262, 2.992155981636289, 2.9921553433497854, 2.992154705888608, 2.992154069250631, 2.99215343343373, 2.9921527984357903, 2.9921521642547058, 2.992151530888378, 2.9921508983347187, 2.992150266591644, 2.992149635657081, 2.9921490055289626, 2.992148376205233, 2.99214774768384, 2.992147119962742, 2.992146493039904, 2.992145866913299, 2.9921452415809084, 2.992144617040721, 2.9921439932907314, 2.992143370328945, 2.9921427481533716, 2.9921421267620323, 2.9921415061529504, 2.992140886324162, 2.9921402672737076, 2.992139648999635, 2.9921390315000007, 2.992138414772868, 2.992137798816307, 2.992137183628394, 2.9921365692072164, 2.992135955550864, 2.992135342657437, 2.992134730525041, 2.992134119151789, 2.992133508535801, 2.992132898675205, 2.9921322895681355, 2.9921316812127325, 2.9921310736071427, 2.9921304667495234, 2.992129860638034, 2.992129255270844, 2.9921286506461273, 2.9921280467620663, 2.9921274436168495, 2.9921268412086723, 2.992126239535735, 2.992125638596247, 2.992125038388422, 2.992124438910482, 2.992123840160655, 2.9921232421371746, 2.9921226448382807, 2.992122048262222, 2.99212145240725, 2.9921208572716256, 2.992120262853614, 2.9921196691514886, 2.9921190761635263, 2.9921184838880115, 2.992117892323237, 2.992117301467498, 2.9921167113190985, 2.992116121876347, 2.9921155331375595, 2.9921149451010574, 2.992114357765165, 2.992113771128219, 2.9921131851885576, 2.9921125999445244, 2.992112015394471, 2.9921114315367565, 2.9921108483697405, 2.9921102658917924, 2.9921096841012873, 2.9921091029966025, 2.9921085225761277, 2.9921079428382504, 2.992107363781369, 2.9921067854038874, 2.992106207704212, 2.992105630680758, 2.992105054331944, 2.992104478656195, 2.992103903651942, 2.9921033293176205, 2.9921027556516715, 2.992102182652542, 2.9921016103186853, 2.992101038648558, 2.9921004676406233, 2.992099897293349, 2.9920993276052092, 2.992098758574683, 2.992098190200254, 2.9920976224804123, 2.992097055413652, 2.9920964889984734, 2.9920959232333804, 2.9920953581168837, 2.992094793647498, 2.992094229823745, 2.9920936666441493, 2.9920931041072407, 2.992092542211555, 2.9920919809556326, 2.992091420338019, 2.9920908603572642, 2.992090301011925, 2.99208974230056, 2.992089184221734, 2.9920886267740174, 2.992088069955986, 2.992087513766219, 2.9920869582033003, 2.992086403265819, 2.99208584895237, 2.99208529526155, 2.992084742191965, 2.992084189742222, 2.992083637910933, 2.9920830866967156, 2.992082536098193, 2.9920819861139907, 2.9920814367427404, 2.9920808879830783, 2.9920803398336435, 2.9920797922930835, 2.9920792453600438, 2.992078699033182, 2.992078153311155, 2.992077608192625, 2.992077063676259, 2.99207651976073, 2.992075976444714, 2.9920754337268907, 2.992074891605944, 2.992074350080565, 2.9920738091494448, 2.9920732688112843, 2.9920727290647817, 2.9920721899086464, 2.9920716513415875, 2.9920711133623192, 2.992070575969561, 2.992070039162036, 2.992069502938472, 2.992068967297599, 2.9920684322381534, 2.9920678977588744, 2.9920673638585065, 2.9920668305357974, 2.992066297789498, 2.9920657656183636, 2.992065234021157, 2.992064702996639, 2.99206417254358, 2.9920636426607508, 2.9920631133469264, 2.9920625846008884, 2.992062056421419, 2.992061528807305, 2.9920610017573406, 2.992060475270319, 2.9920599493450406, 2.9920594239803084, 2.9920588991749284, 2.9920583749277108, 2.992057851237472, 2.992057328103029, 2.9920568055232035, 2.9920562834968223, 2.992055762022714, 2.992055241099712, 2.9920547207266535, 2.9920542009023783, 2.992053681625731, 2.99205316289556, 2.9920526447107156, 2.9920521270700537, 2.9920516099724326, 2.992051093416715, 2.9920505774017667, 2.9920500619264567, 2.9920495469896586, 2.9920490325902485, 2.992048518727106, 2.9920480053991145, 2.9920474926051632, 2.9920469803441394, 2.992046468614938, 2.9920459574164577, 2.9920454467475976, 2.9920449366072632, 2.9920444269943602, 2.9920439179078024, 2.992043409346501, 2.992042901309376, 2.992042393795346, 2.9920418868033387, 2.9920413803322785, 2.9920408743810993, 2.9920403689487323, 2.9920398640341173, 2.9920393596361943, 2.9920388557539073, 2.9920383523862037, 2.9920378495320334, 2.9920373471903505, 2.992036845360112, 2.9920363440402786, 2.9920358432298126, 2.9920353429276796, 2.992034843132851, 2.9920343438442982, 2.9920338450609973, 2.9920333467819273, 2.99203284900607, 2.9920323517324108, 2.9920318549599365, 2.99203135868764, 2.992030862914515, 2.992030367639558, 2.992029872861771, 2.9920293785801553, 2.9920288847937173, 2.9920283915014685]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"GD\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('681a646e-7ab6-4a16-b1c2-39407f539db6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p8mhG0WlUi-"
      },
      "source": [
        "#Stochastic gradient descend implemtned with standard GD class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFQSX5Wy08ga",
        "outputId": "99f889b2-8e0c-4154-c46e-841f59cdfdd0"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class mydataset(Dataset): #accepts numpy\n",
        "    def __init__(self, data, label, transform=None):\n",
        "        self.data = data\n",
        "        self.label = label\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "    def __getitem__(self, idx):\n",
        "        data, labels  = self.data[idx,:], self.label[idx]\n",
        "        return data, labels \n",
        "\n",
        "\n",
        "m = mydataset(data=X_news_train.toarray(), label=y_news_train)\n",
        "dataloader = DataLoader(m, batch_size=64, shuffle=True, num_workers=1, drop_last=True)\n",
        "\n",
        "test_data  = {\"data\"  : csr_matrix(X_news_test),\n",
        "              \"labels\": csr_matrix(y_news_test)}\n",
        "\n",
        "history = {\"step\": [0],\n",
        "          \"function_vals\": [],\n",
        "          \"grad_vals\": [], \n",
        "          \"x_vals\": [csr_matrix(np.zeros((20,20)))], \n",
        "          \"opt_dif\": [],\n",
        "          \"test_loss\": []}\n",
        "\n",
        "for _ in tqdm(range(100)):\n",
        "  for i, (data, labels) in enumerate(dataloader):\n",
        "    # if (i+1) % 197 == 0:\n",
        "    #   pass\n",
        "    train_data = {\"data\"  : csr_matrix(data),\n",
        "                  \"labels\": csr_matrix(labels)}\n",
        "    gd  = GD(csrLogistic_loss(train_data = train_data, test_data = test_data), x_init= None, epochs = 1, learning_rate = lambda s : 0.001)\n",
        "    gd.history = history\n",
        "    gd.go(test = True)\n",
        "    history = gd.history\n",
        "\n",
        "\n",
        "all_history = { \"GD\"  : history}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#~~~~~~~~~~~~~~~~~~~~~~~~~Plots\n",
        "fig = graph.Figure(layout = graph.Layout(title=graph.layout.Title(text=\"GD\")))\n",
        "for i in all_history:\n",
        "    fig.add_trace(graph.Scatter(x    = all_history[i][\"step\"],\n",
        "                                y    = all_history[i][\"function_vals\"],\n",
        "                                name = i))\n",
        "fig.show()\n",
        "\n",
        "# plot the test loss\n",
        "fig = graph.Figure(layout = graph.Layout(title=graph.layout.Title(text=\"GD\")))\n",
        "for i in all_history:\n",
        "    fig.add_trace(graph.Scatter(x    = all_history[i][\"step\"],\n",
        "                                y    = all_history[i][\"test_loss\"],\n",
        "                                name = i))\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 71%|███████   | 71/100 [02:03<00:48,  1.67s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XqfR9pOj1XJ"
      },
      "source": [
        "tqdm._instances.clear()"
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}